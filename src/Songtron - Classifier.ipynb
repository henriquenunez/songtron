{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import imageio\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All functions here receive a binarized image.\n",
    "def bw_ratio(img):\n",
    "    pixel_count = img.size\n",
    "    white_pixels = img[img == 255].size\n",
    "    #print(pixel_count)\n",
    "    #print(img)\n",
    "    #print(img[img == 255].size)\n",
    "    return white_pixels/pixel_count\n",
    "\n",
    "def wh_ratio(img): #Width over height\n",
    "    y, x = img.shape\n",
    "    return x/y\n",
    "\n",
    "def center_mass_ratio(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    \n",
    "    #Okay, first let us compute center of mass of bin image\n",
    "    white_pixels = np.where(img==0)\n",
    "    #This gives us two lists, containing the coordinates.\n",
    "    y_mean = white_pixels[0].sum()/white_pixels[0].size\n",
    "    x_mean = white_pixels[1].sum()/white_pixels[1].size\n",
    "    #Since image is already at origin, we can just use height and width.\n",
    "    return (x_mean/width, y_mean/height)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For binarizing...\n",
    "def otsu_threshold(im):\n",
    "\n",
    "    # Compute histogram and probabilities of each intensity level\n",
    "    pixel_counts = [np.sum(im == i) for i in range(256)]\n",
    "    n, m = im.shape[0:2]\n",
    "    # Initialization\n",
    "    s_max = (0,0)\n",
    "\n",
    "    for threshold in range(256):\n",
    "\n",
    "        # update\n",
    "        w_0 = sum(pixel_counts[:threshold])\n",
    "        w_1 = sum(pixel_counts[threshold:])\n",
    "\n",
    "        mu_0 = sum([i * pixel_counts[i] for i in range(0,threshold)])\\\n",
    "                        / w_0 if w_0 > 0 else 0\n",
    "        mu_1 = sum([i * pixel_counts[i] for i in range(threshold, 256)])\\\n",
    "                        / w_1 if w_1 > 0 else 0\n",
    "\n",
    "        # calculate - inter class variance\n",
    "        s = w_0 * w_1 * (mu_0 - mu_1) ** 2\n",
    "\n",
    "        if s > s_max[1]:\n",
    "            s_max = (threshold, s)\n",
    "    return s_max[0]\n",
    "\n",
    "def threshold(pic, threshold):\n",
    "    return ((pic < threshold) * 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns the above features.\n",
    "def extract_features(img):\n",
    "    center_mass = center_mass_ratio(img)\n",
    "    return (bw_ratio(img), wh_ratio(img), center_mass[0], center_mass[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The feaures we want to analyse are:\n",
    "- Black/White pixel ratio.\n",
    "- Width/Height bounding box ratio.\n",
    "- 'Center of mass' proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1f = \"cropped_num1.0.png\"\n",
    "img_7f = \"cropped_num7.0.png\"\n",
    "img_8f = \"cropped_num8.0.png\"\n",
    "img_9f = \"cropped_num9.0.png\"\n",
    "#Image 1:\n",
    "img_1 = imageio.imread(img_1f)\n",
    "img_1 = threshold(img_1, otsu_threshold(img_1))\n",
    "img_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_ratio(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_ratio(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_mass_ratio(img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "def fill_training_sets(path, X, Y):\n",
    "    note_type = glob.glob(path)\n",
    "    N = 0\n",
    "    for note in note_type:\n",
    "        an_img = imageio.imread(note)\n",
    "        an_img = threshold(an_img, otsu_threshold(an_img))\n",
    "        img_features = extract_features(an_img)\n",
    "        X.append(list(img_features))\n",
    "        Y.append(N)\n",
    "        N+=1\n",
    "\n",
    "#Crotchet\n",
    "#fill_training_sets(\"../assets/reference/crotchet/*\", X, Y)\n",
    "\n",
    "#Minim\n",
    "#fill_training_sets(\"../datasets/minim/*\", X, Y, 2)\n",
    "\n",
    "#G Clef\n",
    "#fill_training_sets(\"../datasets/g_clef/*\", X, Y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a classifier. Receives path to images.\n",
    "def build_classifier(path):\n",
    "    X = []\n",
    "    Y = []\n",
    "    fill_training_sets(path, X, Y)\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "    clf.fit(X,Y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here the classifier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6864864864864865,\n",
       " 0.40540540540540543,\n",
       " 0.5486590038314176,\n",
       " 0.7576887232059646)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_node = imageio.imread(test)\n",
    "test_node = threshold(test_node, otsu_threshold(test_node))\n",
    "test_feat = extract_features(test_node)\n",
    "test_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier for crotchet\n",
    "cr_clf = build_classifier(\"../assets/reference/crotchet/*\")\n",
    "clef_clf = build_classifier(\"../assets/reference/clef/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06 0.24 0.   0.06 0.   0.   0.   0.08 0.2  0.2  0.14 0.   0.02 0.  ]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "print(cr_clf.predict_proba([test_feat]))\n",
    "print(clef_clf.predict_proba([test_feat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_clf.predict([test_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (symbol_classifier.py, line 38)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/hiram/Workspace/miniconda3/envs/imgproc/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-fbeed4cb7d2b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import symbol_classifier\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/hiram/Workspace/SongTron/src/symbol_classifier.py\"\u001b[0;36m, line \u001b[0;32m38\u001b[0m\n\u001b[0;31m    return (bw_ratio(img), wh_ratio(img), center_mass[0], center_mass[1])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import symbol_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
